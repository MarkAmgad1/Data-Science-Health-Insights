{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea2d523b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m enable_iterative_imputer\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimpute\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterativeImputer\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input, Dense\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimizers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Adam\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ad7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 Load data with custom missing value recognition\n",
    "df = pd.read_csv('framingham.csv', na_values=[\"NA\", \"N/A\", \"\", \" \", \"null\", \"?\"])\n",
    "\n",
    "# Basic info\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "\n",
    "# 🔍 Missing Data Analysis\n",
    "missing_counts = df.isnull().sum()\n",
    "missing_percent = (missing_counts / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_counts,\n",
    "    'Missing %': missing_percent\n",
    "}).sort_values(by='Missing %', ascending=False)\n",
    "\n",
    "print(\"\\nMissing Data Overview:\\n\", missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "# 🌡️ Visualize\n",
    "\n",
    "focus_cols = ['glucose', 'education', 'BPMeds', 'totChol', 'cigsPerDay', 'BMI', 'heartRate']\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df[focus_cols].isnull(), cbar=False, cmap='viridis')\n",
    "plt.title(\"Missing Data Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b080388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indicator columns for missingness\n",
    "df['glucose_missing'] = df['glucose'].isnull().astype(int)\n",
    "df['BPMeds_missing'] = df['BPMeds'].isnull().astype(int)\n",
    "df['cigsPerDay_missing'] = df['cigsPerDay'].isnull().astype(int)\n",
    "\n",
    "# Plot glucose missingness vs age\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df, x='glucose_missing', y='age')\n",
    "plt.title('Age vs Missing Glucose (Check for MAR)')\n",
    "plt.show()\n",
    "\n",
    "# Plot BPMeds missingness vs prevalentHyp\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='prevalentHyp', hue='BPMeds_missing')\n",
    "plt.title('prevalentHyp vs Missing BPMeds')\n",
    "plt.show()\n",
    "\n",
    "# Plot cigsPerDay missingness vs currentSmoker\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='currentSmoker', hue='cigsPerDay_missing')\n",
    "plt.title('Smoking Status vs Missing cigsPerDay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29371f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# اختار الأعمدة اللي فيها missing\n",
    "columns_with_na = ['glucose', 'education', 'BPMeds', 'totChol', 'cigsPerDay', 'BMI', 'heartRate']\n",
    "\n",
    "# نسخة من الداتا علشان نحافظ على الأصل\n",
    "df_basic = df.copy()\n",
    "\n",
    "# --- Mean Imputation ---\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "df_basic[['glucose', 'totChol', 'BMI', 'heartRate']] = mean_imputer.fit_transform(df_basic[['glucose', 'totChol', 'BMI', 'heartRate']])\n",
    "\n",
    "# --- Median Imputation ---\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "df_basic[['cigsPerDay']] = median_imputer.fit_transform(df_basic[['cigsPerDay']])\n",
    "\n",
    "# --- Mode Imputation (for categorical-like variables) ---\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_basic[['education', 'BPMeds']] = mode_imputer.fit_transform(df_basic[['education', 'BPMeds']])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(df_basic[columns_with_na].isnull(), cbar=False, cmap='crest')\n",
    "plt.title(\"Missing Values After Basic Imputation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18754a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_knn = df.copy()\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_knn[columns_with_na] = knn_imputer.fit_transform(df_knn[columns_with_na])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(df_knn[columns_with_na].isnull(), cbar=False, cmap='viridis')\n",
    "plt.title(\"Missing Values After KNN Imputation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mice = df.copy()\n",
    "mice_imputer = IterativeImputer(random_state=0)\n",
    "df_mice[columns_with_na] = mice_imputer.fit_transform(df_mice[columns_with_na])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(df_mice[columns_with_na].isnull(), cbar=False, cmap='plasma')\n",
    "plt.title(\"Missing Values After MICE Imputation\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a63722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df.copy()\n",
    "\n",
    "# الخطوة 1: نختار الأعمدة اللي هنستخدمها كـ features\n",
    "features = ['age', 'BMI', 'totChol', 'heartRate']\n",
    "\n",
    "# الخطوة 2: نحذف الصفوف اللي فيها missing في أي عمود من الـ features أو glucose\n",
    "df_reg_filtered = df_reg.dropna(subset=features + ['glucose'])\n",
    "\n",
    "# الخطوة 3: نقسم البيانات train/test حسب glucose\n",
    "train = df_reg_filtered[df_reg_filtered['glucose'].notnull()]\n",
    "test = df_reg_filtered[df_reg_filtered['glucose'].isnull()]  # ده هيطلع فاضي غالبًا بعد dropna\n",
    "\n",
    "# الخطوة 4: تدريب الموديل\n",
    "reg = LinearRegression()\n",
    "reg.fit(train[features], train['glucose'])\n",
    "\n",
    "# لو فيه test حقيقي (يعني صفوف كانت glucose ناقصة)، نعمل predict ونرجع نحطها\n",
    "if not test.empty:\n",
    "    predicted_glucose = reg.predict(test[features])\n",
    "    df_reg.loc[test.index, 'glucose'] = predicted_glucose\n",
    "else:\n",
    "    print(\"No missing glucose values left to predict after cleaning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ea9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# نحضّر البيانات\n",
    "df_dl = df.copy()\n",
    "df_dl_subset = df_dl[columns_with_na].copy()\n",
    "\n",
    "# نعمل impute مبدئي بسيط (مثلاً بـ mean) عشان نقدر نديها للـ neural network\n",
    "df_dl_imputed = df_dl_subset.fillna(df_dl_subset.mean())\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df_dl_imputed)\n",
    "\n",
    "# Autoencoder architecture\n",
    "input_dim = df_scaled.shape[1]\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(16, activation='relu')(input_layer)\n",
    "encoded = Dense(8, activation='relu')(encoded)\n",
    "decoded = Dense(16, activation='relu')(encoded)\n",
    "output_layer = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(df_scaled, df_scaled, epochs=100, batch_size=32, shuffle=True, verbose=0)\n",
    "\n",
    "# Predict (reconstruct) the data\n",
    "reconstructed = autoencoder.predict(df_scaled)\n",
    "\n",
    "# Inverse scaling\n",
    "df_reconstructed = scaler.inverse_transform(reconstructed)\n",
    "df_imputed_deep = pd.DataFrame(df_reconstructed, columns=columns_with_na)\n",
    "\n",
    "# Replace missing values ONLY where original was missing\n",
    "for col in columns_with_na:\n",
    "    df_dl.loc[df_dl[col].isnull(), col] = df_imputed_deep.loc[df_dl[col].isnull(), col]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
